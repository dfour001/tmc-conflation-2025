{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import shapely\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrs_tools import gp_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.DEBUG) # Set the debug level here\n",
    "fileHandler = logging.FileHandler(f'test.log', mode='w')\n",
    "log.addHandler(fileHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lrs_tools.gp_lrs' from 'c:\\\\Users\\\\daniel.fourquet\\\\Documents\\\\Tasks\\\\TMC Conflation 2025\\\\NPMRDS\\\\lrs_tools\\\\gp_lrs.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gp_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lrs to an LRS object\n",
    "lrs_path = r'C:\\Users\\daniel.fourquet\\Documents\\Tasks\\TMC Conflation 2025\\Data\\LRS_MASTER_RICHMOND_SINGLEPART.shp'\n",
    "\n",
    "# Filter to only include NB and EB routes, excluding PA and Interstates.  Exclude ramps\n",
    "lrs = gp_lrs.LRS(lrs_path, filter=True, ramps=0)\n",
    "\n",
    "# Load lrs overlap to an LRS object\n",
    "lrs_overlap_path = r'C:\\Users\\daniel.fourquet\\Documents\\Tasks\\TMC Conflation 2025\\Data\\LRS_OVERLAP_RICHMOND.shp'\n",
    "\n",
    "# Filter to only include NB and EB routes, excluding PA and Interstates.  Exclude ramps\n",
    "lrs_overlap = gp_lrs.LRS(lrs_overlap_path, filter=True, ramps=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ArcGIS_Python\\arcgispro-py3-fourquet\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "c:\\ArcGIS_Python\\arcgispro-py3-fourquet\\lib\\site-packages\\geopandas\\geoseries.py:924: ShapelyDeprecationWarning: The 'type' attribute is deprecated, and will be removed in the future. You can use the 'geom_type' attribute instead.\n",
      "  if s.type.startswith(\"Multi\") or s.type == \"GeometryCollection\":\n"
     ]
    }
   ],
   "source": [
    "# Load TMCs to a GeoDataFrame\n",
    "tmcs_path = r'C:\\Users\\daniel.fourquet\\Documents\\Tasks\\TMC Conflation 2025\\NPMRDS\\data\\NPMRDS_medium_test.shp'\n",
    "tmcs = gp.read_file(tmcs_path)\n",
    "tmcs = tmcs[['Tmc', 'RoadNumber', 'RoadName', 'TmcLinear', 'geometry']]\n",
    "tmcs = tmcs.to_crs(epsg=3968)\n",
    "\n",
    "# Calculate begin, end, and mid-points\n",
    "tmcs['begin_point'] = shapely.get_point(tmcs['geometry'], 0)\n",
    "tmcs['end_point'] = shapely.get_point(tmcs['geometry'], -1)\n",
    "def get_midpoint(geom):\n",
    "    return geom.interpolate(0.5, normalized=True)\n",
    "tmcs['mid_point'] = tmcs.geometry.apply(get_midpoint)\n",
    "\n",
    "# Get TMCs dissolved by lineartmc\n",
    "linear_tmcs = tmcs.dissolve(['TmcLinear', 'RoadName']).reset_index()\n",
    "linear_tmcs['geometry'] = shapely.line_merge(linear_tmcs.geometry)\n",
    "linear_tmcs = linear_tmcs.explode()\n",
    "def interpolate(geom, pct):\n",
    "    return geom.interpolate(pct, normalized=True)\n",
    "linear_tmcs['begin_point'] = linear_tmcs.geometry.apply(interpolate, pct=0)\n",
    "linear_tmcs['mid_point'] = linear_tmcs.geometry.apply(interpolate, pct=0.5)\n",
    "linear_tmcs['end_point'] = linear_tmcs.geometry.apply(interpolate, pct=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most common routes near linear tmcs.  Only return results with one match\n",
    "def match_routes__begin_mid_end_points(tmc, distance=15, point_threshold=3, lrs=lrs):\n",
    "    log.debug(f'\\n{\"=\"*10}')\n",
    "    log.debug(f'\\n{tmc[\"Tmc\"]} - Match Routes by Points - Distance: {distance}')\n",
    "    \n",
    "    points = (tmc['begin_point'], tmc['mid_point'], tmc['end_point'])\n",
    "    \n",
    "    log.debug('points:')\n",
    "    for point in points:\n",
    "        log.debug(f'\\t{point}')\n",
    "\n",
    "    routes = Counter()\n",
    "    for point in points:\n",
    "        nearby_routes = gp_lrs.get_nearby_routes(point, distance, lrs)\n",
    "        routes.update(nearby_routes)\n",
    "\n",
    "    # Check for no matches\n",
    "    if len(routes) == 0:\n",
    "        log.debug('\\tNo matches.  Returning None')\n",
    "        return None\n",
    "\n",
    "    log.debug(f'\\tRoutes:  {routes}')\n",
    "\n",
    "    # If the number of points that match with a single route is equal\n",
    "    # to the point_threshold, it is likely a match.  Otherwise a  more\n",
    "    # precise method is needed.\n",
    "    most_common_count = routes.most_common(1)[0][1]\n",
    "    if most_common_count < point_threshold:\n",
    "        log.debug('\\tMost common below threshold.  Returning None')\n",
    "        return None\n",
    "    \n",
    "    most_common_routes = routes.most_common()\n",
    "\n",
    "    # Find the maximum count\n",
    "    max_count = most_common_routes[0][1]\n",
    "\n",
    "    # Filter for elements with the maximum count\n",
    "    result = [element for element, count in most_common_routes if count == max_count]\n",
    "\n",
    "    if len(result) == 1:\n",
    "        log.debug(f'Returning {result[0]}')\n",
    "        return result[0]\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get most common routes\n",
    "log.debug(f'===\\nLinear TMC IDs - match_routes__begin_mid_end_points\\n===')\n",
    "linear_tmcs['rte_nm_match'] = linear_tmcs.apply(match_routes__begin_mid_end_points, axis=1)\n",
    "\n",
    "# Remove null values.  These will need to be matched at the tmc level\n",
    "linear_tmcs = linear_tmcs.loc[linear_tmcs['rte_nm_match'].notnull()].copy()\n",
    "\n",
    "# Reduce to only needed columns to join back to the tmc dataframe\n",
    "linear_tmcs = linear_tmcs.reset_index()[['TmcLinear', 'RoadName', 'rte_nm_match']].drop_duplicates()\n",
    "\n",
    "# Remove any linear tmc id that appears more than once\n",
    "linear_tmcs = linear_tmcs[~linear_tmcs.duplicated(['TmcLinear', 'RoadName'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tmcs and linear_tmcs by TmcLinear\n",
    "tmcs = tmcs.merge(linear_tmcs, how='left', on=['TmcLinear', 'RoadName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null values: 68\n"
     ]
    }
   ],
   "source": [
    "print(f\"Remaining null values: {len(tmcs.loc[tmcs['rte_nm_match'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null values: 21\n"
     ]
    }
   ],
   "source": [
    "# Match by TMC, but only on tmcs where rte_nm_match is null\n",
    "tmcs_no_match = tmcs.loc[tmcs['rte_nm_match'].isnull()].copy()\n",
    "\n",
    "log.debug(f'===\\TMCs - match_routes__begin_mid_end_points\\n===')\n",
    "tmcs_no_match['rte_nm_match'] = tmcs_no_match.apply(match_routes__begin_mid_end_points, axis=1)\n",
    "tmcs_no_match = tmcs_no_match[['Tmc', 'rte_nm_match']]\n",
    "\n",
    "# Join back to main tmcs\n",
    "tmcs = tmcs.merge(tmcs_no_match, how='left', on='Tmc', suffixes=('', '_new')).fillna(tmcs_no_match)\n",
    "tmcs.loc[tmcs['rte_nm_match'].isnull(), 'rte_nm_match'] = tmcs['rte_nm_match_new']\n",
    "tmcs.drop(columns='rte_nm_match_new', axis=1, inplace=True)\n",
    "\n",
    "print(f\"Remaining null values: {len(tmcs.loc[tmcs['rte_nm_match'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null values: 20\n"
     ]
    }
   ],
   "source": [
    "# Match by TMC again with a lower search radius, but only on tmcs where rte_nm_match is null\n",
    "tmcs_no_match = tmcs.loc[tmcs['rte_nm_match'].isnull()].copy()\n",
    "\n",
    "log.debug(f'===\\TMCs - match_routes__begin_mid_end_points - low search radius\\n===')\n",
    "tmcs_no_match['rte_nm_match'] = tmcs_no_match.apply(match_routes__begin_mid_end_points, distance=5, axis=1)\n",
    "tmcs_no_match = tmcs_no_match[['Tmc', 'rte_nm_match']]\n",
    "\n",
    "# Join back to main tmcs\n",
    "tmcs = tmcs.merge(tmcs_no_match, how='left', on='Tmc', suffixes=('', '_new')).fillna(tmcs_no_match)\n",
    "tmcs.loc[tmcs['rte_nm_match'].isnull(), 'rte_nm_match'] = tmcs['rte_nm_match_new']\n",
    "tmcs.drop(columns='rte_nm_match_new', axis=1, inplace=True)\n",
    "\n",
    "print(f\"Remaining null values: {len(tmcs.loc[tmcs['rte_nm_match'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null values: 12\n"
     ]
    }
   ],
   "source": [
    "# Match by TMC again with a higher search radius, but only on tmcs where rte_nm_match is null\n",
    "tmcs_no_match = tmcs.loc[tmcs['rte_nm_match'].isnull()].copy()\n",
    "\n",
    "log.debug(f'===\\TMCs - match_routes__begin_mid_end_points - low search radius\\n===')\n",
    "tmcs_no_match['rte_nm_match'] = tmcs_no_match.apply(match_routes__begin_mid_end_points, distance=25, axis=1)\n",
    "tmcs_no_match = tmcs_no_match[['Tmc', 'rte_nm_match']]\n",
    "\n",
    "# Join back to main tmcs\n",
    "tmcs = tmcs.merge(tmcs_no_match, how='left', on='Tmc', suffixes=('', '_new')).fillna(tmcs_no_match)\n",
    "tmcs.loc[tmcs['rte_nm_match'].isnull(), 'rte_nm_match'] = tmcs['rte_nm_match_new']\n",
    "tmcs.drop(columns='rte_nm_match_new', axis=1, inplace=True)\n",
    "\n",
    "print(f\"Remaining null values: {len(tmcs.loc[tmcs['rte_nm_match'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null values: 11\n"
     ]
    }
   ],
   "source": [
    "# Match by TMC again, but using the overlap lrs instead\n",
    "tmcs_no_match = tmcs.loc[tmcs['rte_nm_match'].isnull()].copy()\n",
    "\n",
    "log.debug(f'===\\TMCs - match_routes__begin_mid_end_points - overlap LRS\\n===')\n",
    "tmcs_no_match['rte_nm_match'] = tmcs_no_match.apply(match_routes__begin_mid_end_points, distance=25, lrs=lrs_overlap, axis=1)\n",
    "tmcs_no_match = tmcs_no_match[['Tmc', 'rte_nm_match']]\n",
    "\n",
    "# Join back to main tmcs\n",
    "tmcs = tmcs.merge(tmcs_no_match, how='left', on='Tmc', suffixes=('', '_new')).fillna(tmcs_no_match)\n",
    "tmcs.loc[tmcs['rte_nm_match'].isnull(), 'rte_nm_match'] = tmcs['rte_nm_match_new']\n",
    "tmcs.drop(columns='rte_nm_match_new', axis=1, inplace=True)\n",
    "\n",
    "print(f\"Remaining null values: {len(tmcs.loc[tmcs['rte_nm_match'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_routes__line_segments(record, frequency=5, detailed_search=False):\n",
    "    log.debug(f'\\n{\"=\"*10}')\n",
    "    log.debug(f'\\n{record[\"Tmc\"]} - Match Routes by Segments')\n",
    "\n",
    "    # Break input geometry into a list of individual line segments\n",
    "    coords = record.geometry.coords\n",
    "    segments = []\n",
    "    for i in range(len(coords)):\n",
    "        begin_point = coords[i-1]\n",
    "        end_point = coords[i]\n",
    "        segment = LineString((begin_point, end_point))\n",
    "        segments.append(segment)\n",
    "\n",
    "    if len(segments[1::frequency]) < frequency:\n",
    "        frequency = 2  # Ensures that shorter segments get enough sample points\n",
    "\n",
    "    if detailed_search:\n",
    "        frequency = 1  # If detailed search, then all segments should be checked\n",
    "\n",
    "    #  Reduce list to every {frequency} segment to improve processing time\n",
    "    segments = segments[1::frequency]  # Ignore first segment because it contains begin and end point\n",
    "    log.debug(f'\\t{len(segments)} test segments')\n",
    "\n",
    "    # For each segment, find matching nearby routes\n",
    "    routes = []\n",
    "    for segment in segments:\n",
    "        nearby_routes = gp_lrs.get_nearby_route_by_segments(segment, 15, lrs)\n",
    "        routes.extend(nearby_routes)\n",
    "        \n",
    "    # Check for no matches\n",
    "    if len(routes) == 0:\n",
    "        log.debug('\\tNo matches.  Returning None')\n",
    "        return None\n",
    "\n",
    "    log.debug(f'\\tAll Routes:  {routes}')\n",
    "\n",
    "    # If only one segment tested and only one result, return the result\n",
    "    if len(routes) == 1 and len(segments) == 1:\n",
    "        return routes[0]\n",
    "\n",
    "    # Keeps elements in a list that have a consecutive duplicate.\n",
    "    route_list = []\n",
    "    i = 0\n",
    "    while i < len(routes) - 1:\n",
    "        if routes[i] == routes[i + 1]:\n",
    "            route_list.extend([routes[i], routes[i + 1]])\n",
    "            i += 2  # Skip the next element since it's already included\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    route_list = list(set(route_list))\n",
    "\n",
    "    # If no matches found and this is not a detailed search, try again\n",
    "    # but include all segments\n",
    "    if len(route_list) == 0 and detailed_search == False:\n",
    "        return match_routes__line_segments(record, detailed_search=True)\n",
    "\n",
    "    log.debug(f'\\tReturning Routes:  {route_list}')\n",
    "\n",
    "    return ','.join(route_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null values: 0\n"
     ]
    }
   ],
   "source": [
    "null_filter = (tmcs['rte_nm_match'].isnull())\n",
    "# null_filter = (tmcs['Tmc'] == '110N18081')\n",
    "tmcs.loc[null_filter, 'rte_nm_match'] = tmcs.loc[null_filter].apply(match_routes__line_segments, axis=1)\n",
    "\n",
    "print(f\"Remaining null values: {len(tmcs.loc[tmcs['rte_nm_match'].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Records with more than one rte_nm in the rte_nm_match field should get new records\n",
    "\n",
    "# Identify rows with multiple values\n",
    "tmcs['multiple_values'] = tmcs['rte_nm_match'].str.contains(',')\n",
    "\n",
    "# Explode the multiple values\n",
    "tmcs_exploded = tmcs.assign(rte_nm_match=tmcs['rte_nm_match'].str.split(',')).explode('rte_nm_match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 499\n"
     ]
    }
   ],
   "source": [
    "print(len(tmcs), len(tmcs_exploded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('arcgispro-py3-fourquet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e95fc3596777a0a2d8d076aaffa1168baaa9b19b375f97135299284ce211fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
